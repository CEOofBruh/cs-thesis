{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eeyvee-0x4d/cs-thesis/blob/main/Notebook/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWdQ3Ic7Yagi"
      },
      "source": [
        "<h1>Clone repository</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo9WC5LBymdt",
        "outputId": "bf655210-9e0c-43c2-9982-cc0f06739174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaFgOkofymd4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "\n",
        "df = pd.read_csv('/gdrive/MyDrive/vaccination_all_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6U4f5en07He"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['id', 'user_description', 'user_created', 'user_followers', 'user_friends', 'user_favourites', 'user_verified', 'hashtags', 'source', 'retweets', 'favorites', 'is_retweet'])\n",
        "df.to_csv(path_or_buf='/content/tweets.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEUhwLHG8JpF"
      },
      "outputs": [],
      "source": [
        "txtfile = open('/content/locations.txt', 'r')\n",
        "locations = txtfile.read().splitlines()\n",
        "\n",
        "df = pd.read_csv('/content/tweets.csv')\n",
        "tweets = df[df['user_location'].isin(locations)]\n",
        "tweets.to_csv(path_or_buf='/content/tweets.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6V5eVRbMm5e",
        "outputId": "2727088c-996b-458e-d03a-5df20d273f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'thesis'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (834/834), done.\u001b[K\n",
            "remote: Compressing objects: 100% (599/599), done.\u001b[K\n",
            "remote: Total 834 (delta 275), reused 690 (delta 203), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (834/834), 101.46 MiB | 19.56 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n",
            "/content/thesis\n",
            "client\tDataset  kaggle_tweets.csv  Notebook  README.md  server  StreamingAPI\n"
          ]
        }
      ],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/eeyvee-0x4d/cs-thesis thesis\n",
        "%cd thesis\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RImCpBW1LApR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7jw9rEvakhs"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/thesis/Dataset/Annotated-Compilation.csv', encoding='cp1252')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvXR9EvKZB0Y"
      },
      "source": [
        "<h1>Text Preprocessing</h1>\n",
        "<ul>\n",
        "  <li>Import dataset</li>\n",
        "  <li>Remove urls</li>\n",
        "  <li>Remove special characters</li>\n",
        "  <li>Convert text data to lowercase</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X-VQ9aBDLDM3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/thesis/Dataset/trainingdata.csv') #read csv\n",
        "\n",
        "df_shape = df.shape # (row, column)\n",
        "\n",
        "# remove urls, remove special chars, conver to lowercase\n",
        "for i in range(df_shape[0]):\n",
        "  string = re.sub(r'http\\S+', '', df.at[i, 'Text']).lower()\n",
        "  df.at[i, 'Text'] = re.sub(r'\\n', '', string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlDyDPZA-VV9"
      },
      "source": [
        "<h1>Natural Language Toolkit NLTK</h1>\n",
        "<p>\n",
        "Nltk will be used to preprocess to corpus.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhuqMaQU6Lwb",
        "outputId": "943766e7-d122-442b-9db9-37acb6b54e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stopwordsiso\n",
            "  Downloading stopwordsiso-0.6.1-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 40 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 51 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 61 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 71 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 73 kB 1.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: stopwordsiso\n",
            "Successfully installed stopwordsiso-0.6.1\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip install stopwordsiso\n",
        "\n",
        "import nltk\n",
        "import stopwordsiso\n",
        "\n",
        "from nltk.stem import *\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c1TpyQH-1JW"
      },
      "source": [
        "<h1>Stemming words using Porter Stemmer</h1>\n",
        "<p>\n",
        "Apply porter stemmer to each tokens first then rebuild the tokens into sentence.\n",
        "</p>\n",
        "<hr>\n",
        "<h1>Stop words removal</h1>\n",
        "<p>\n",
        "Remove stop words in english and tagalog.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WyqpJpwL6lYO"
      },
      "outputs": [],
      "source": [
        "corpus = df[\"Text\"]\n",
        "\n",
        "stemmer = PorterStemmer() # Porter Stemmer\n",
        "\n",
        "stopwords_eng = set(stopwords.words('english')) # English stopwords\n",
        "stopwords_tl  = set(stopwordsiso.stopwords('tl'))\n",
        "filtered_sentence = []\n",
        "filtered_sentence2 = []\n",
        "\n",
        "for i in range(len(df['Text'])):\n",
        "  document = df.loc[i, 'Text']\n",
        "  tokens = nltk.word_tokenize(document)\n",
        "\n",
        "  stemmed_tokens = [stemmer.stem(token) for token in tokens] # stem each words\n",
        "  filtered_sentence = [token for token in stemmed_tokens if not token in stopwords_eng] # remove english stopwords\n",
        "  filtered_sentence2 = [token for token in filtered_sentence if not token in stopwords_tl] #remove tagalog stopwords\n",
        "\n",
        "  document = \" \".join(filtered_sentence2)\n",
        "  df.loc[i, 'Text'] = document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FN438rY_aOV"
      },
      "source": [
        "# Create train data and test data\n",
        "\n",
        "Create train data and test data using 2:1 ration. Use `train_test_split` for this.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Create n-grams from 1-4 ?\n",
        "\n",
        "Create n-grams from 1 to 4 for exprementational purposes. Use params `ngram_range=(1,1)`, `ngram_range=(1,2)`, `ngram_range=(1,3)`, `ngram_range=(1,4)` in `TfidfVectorizer(ngram_range=(1,1))`.\n",
        "Default is `ngram_range=(1,1)`\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Perform TF-IDF to the corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "wKLdAMszBeEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7e32eb-8a95-45a1-8143-d3b1936243f6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Sentiment']) # split dataset into train set and test set.\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "#x = text\n",
        "#y = labels"
      ],
      "metadata": {
        "id": "t7uGbgg2P_Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eafc5e-97fd-4b77-fe78-74a90ea0811b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(738,)\n",
            "(738,)\n",
            "(246,)\n",
            "(246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['Text']\n",
        "y = df['Sentiment']\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lt5YDqcSMh2",
        "outputId": "7c7403e9-28d3-4edb-d862-96f73735d0db"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    752\n",
              "0    232\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-gram\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4)) # Initialize vectorizer\n",
        "x_train_features = vectorizer.fit_transform(x)\n",
        "# x_test_features = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "wVysZhaQSQoi"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "# define oversampling strategy\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "x_oversampled, y_oversampled = oversample.fit_resample(x_train_features, y)"
      ],
      "metadata": {
        "id": "tL9EFzY1FxM5"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Unvalidated data\n",
        "##### unigram\n",
        "\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.8433725005153578|0\\.9067234670711187|0\\.837956268254642|0\\.9893333333333333|\n",
        "|1|0\\.1|0\\.8983405483405482|0\\.9327723203061895|0\\.9406336889242061|0\\.9267719298245615|\n",
        "|2|0\\.01|0\\.899340342197485|0\\.9327440790656707|0\\.9458449249506972|0\\.9214385964912282|\n",
        "|3|0\\.001|0\\.8922180993609565|0\\.9281631520729385|0\\.9354407746148251|0\\.9227543859649122|\n",
        "|4|0\\.0001|0\\.886105957534529|0\\.9246591113401206|0\\.9266756053486711|0\\.9240877192982456|\n",
        "|5|1e-05|0\\.8820449391877963|0\\.9221884015807955|0\\.9218514052853953|0\\.9240877192982456|\n",
        "\n",
        "##### Oversampled\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.9521324503311259|0\\.9499405203442693|0\\.9794461997362995|0\\.9241052631578949|\n",
        "|1|0\\.1|0\\.9554525386313465|0\\.9533241530524375|0\\.9876281613123717|0\\.9227719298245616|\n",
        "|2|0\\.01|0\\.9554392935982341|0\\.9531634283173396|0\\.9875497145391661|0\\.9227543859649122|\n",
        "|3|0\\.001|0\\.9547770419426049|0\\.9525383134065105|0\\.9862559550262284|0\\.9227543859649122|\n",
        "|4|0\\.0001|0\\.9547814569536426|0\\.9527225059628208|0\\.9849743419025101|0\\.9240877192982456|\n",
        "|5|1e-05|0\\.9554481236203092|0\\.9535394994268731|0\\.9849743419025101|0\\.9254210526315789|\n",
        "\n",
        "##### bigram\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.8058338486909916|0\\.8870131045503321|0\\.8007805586879021|0\\.9946666666666667|\n",
        "|1|0\\.1|0\\.883044733044733|0\\.9198779621790887|0\\.9493961578963102|0\\.8947894736842106|\n",
        "|2|0\\.01|0\\.8698309626881056|0\\.9078215343401377|0\\.9654297527327534|0\\.8615087719298247|\n",
        "|3|0\\.001|0\\.8769532055246341|0\\.9145601253543392|0\\.9546724465501502|0\\.8814736842105264|\n",
        "|4|0\\.0001|0\\.8789837146980004|0\\.9172551137078895|0\\.9442490419115984|0\\.8948070175438596|\n",
        "|5|1e-05|0\\.8769532055246341|0\\.916725993662902|0\\.9354774278902702|0\\.9014561403508772|\n",
        "\n",
        "##### Oversampled\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.9594437086092716|0\\.9576599408423313|0\\.9808222788865244|0\\.9374035087719298|\n",
        "|1|0\\.1|0\\.9694172185430464|0\\.9681659122380083|0\\.9896391279952923|0\\.9494210526315789|\n",
        "|2|0\\.01|0\\.9660794701986755|0\\.9644538888042138|0\\.9922077922077921|0\\.9400877192982456|\n",
        "|3|0\\.001|0\\.9620971302428256|0\\.9603240272426181|0\\.992034632034632|0\\.9320877192982457|\n",
        "|4|0\\.0001|0\\.9627637969094923|0\\.9610424180472157|0\\.992034632034632|0\\.9334210526315789|\n",
        "|5|1e-05|0\\.9627637969094923|0\\.9610424180472157|0\\.992034632034632|0\\.9334210526315789|\n",
        "\n",
        "##### trigram\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.794671201814059|0\\.8814627714049127|0\\.7899591928578678|0\\.9973333333333333|\n",
        "|1|0\\.1|0\\.8627190270047412|0\\.9032874487637794|0\\.9588054154178642|0\\.8574736842105264|\n",
        "|2|0\\.01|0\\.826149247577819|0\\.869656355174962|0\\.9822107527437753|0\\.7869298245614035|\n",
        "|3|0\\.001|0\\.8484951556380128|0\\.8902175463398383|0\\.9741420880560527|0\\.8242456140350878|\n",
        "|4|0\\.0001|0\\.8556380127808699|0\\.8977069801866697|0\\.9570132861241067|0\\.849561403508772|\n",
        "|5|1e-05|0\\.8566687280972995|0\\.9002367045804576|0\\.945278833891248|0\\.8628771929824561|\n",
        "\n",
        "##### Oversampled\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.9634216335540838|0\\.9613803560865797|0\\.9918488102049746|0\\.9347368421052632|\n",
        "|1|0\\.1|0\\.9714083885209714|0\\.9702352111718398|0\\.9906287329848974|0\\.9520701754385964|\n",
        "|2|0\\.01|0\\.9694172185430464|0\\.9682717560035832|0\\.9905726837850125|0\\.9480877192982454|\n",
        "|3|0\\.001|0\\.9674172185430464|0\\.9659486883127437|0\\.9918173310296599|0\\.9427543859649123|\n",
        "|4|0\\.0001|0\\.965421633554084|0\\.9638334137047426|0\\.9917792792792792|0\\.9387719298245614|\n",
        "|5|1e-05|0\\.9647549668874174|0\\.9631150229001448|0\\.9917792792792792|0\\.9374385964912282|\n",
        "\n",
        "##### 4-gram\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.7885899814471243|0\\.8783597832110669|0\\.7849599461238876|0\\.9973333333333333|\n",
        "|1|0\\.1|0\\.8464543393114822|0\\.8900207186160214|0\\.9630631044652457|0\\.8308421052631578|\n",
        "|2|0\\.01|0\\.7915378272521129|0\\.8384571396332458|0\\.9877403678969146|0\\.7363508771929824|\n",
        "|3|0\\.001|0\\.8180169037311895|0\\.8627812689624499|0\\.9820070191164824|0\\.776280701754386|\n",
        "|4|0\\.0001|0\\.8383426097711812|0\\.881035820124733|0\\.9753038823036937|0\\.8095789473684212|\n",
        "|5|1e-05|0\\.8464852607709752|0\\.8898393897152944|0\\.9591019619652146|0\\.8348947368421052|\n",
        "\n",
        "##### Oversampled\n",
        "|index|param\\_alpha|mean\\_test_accuracy|mean\\_test_f1|mean\\_test_precision|mean\\_test_recall|\n",
        "|---|---|---|---|---|---|\n",
        "|0|1|0\\.9667549668874171|0\\.9654714043194442|0\\.9893277893277894|0\\.9440701754385964|\n",
        "|1|0\\.1|0\\.9787284768211922|0\\.9783008516855206|0\\.9907714741398952|0\\.966719298245614|\n",
        "|2|0\\.01|0\\.9734172185430465|0\\.972787879198138|0\\.9883062883062884|0\\.9587368421052631|\n",
        "|3|0\\.001|0\\.9694216335540838|0\\.9685428172449685|0\\.989468066180395|0\\.9494210526315789|\n",
        "|4|0\\.0001|0\\.9667637969094922|0\\.9655854963797628|0\\.9893445735550997|0\\.9441052631578948|\n",
        "|5|1e-05|0\\.9647637969094923|0\\.9633842416790085|0\\.9893445735550997|0\\.9401052631578949|\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F3MUeuKS4eSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "8SIAP8GYm_wu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
        "scorers = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score)\n",
        "}\n",
        "scoring  = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score), }\n",
        "mnb = MultinomialNB()\n",
        "classifier = GridSearchCV(mnb, parameters, return_train_score=False, cv=10, scoring=scorers, refit='accuracy')\n",
        "classifier.fit(x_oversampled, y_oversampled)"
      ],
      "metadata": {
        "id": "ntsQZqyfnKKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6240c3a2-9138-4f1e-cb10-128b852001d7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
              "             param_grid={'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
              "             refit='accuracy',\n",
              "             scoring={'accuracy': make_scorer(accuracy_score),\n",
              "                      'f1': make_scorer(f1_score),\n",
              "                      'precision': make_scorer(precision_score),\n",
              "                      'recall': make_scorer(recall_score)})"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(classifier.cv_results_)\n",
        "results[['param_alpha', 'mean_test_accuracy', 'mean_test_f1', 'mean_test_precision', 'mean_test_recall']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "3kkXVJ0va9hw",
        "outputId": "be1b693d-c779-4cbd-bbbe-cedcc94301bf"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c04f612-abd6-4d94-b9f7-43327d2cdd4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>mean_test_f1</th>\n",
              "      <th>mean_test_precision</th>\n",
              "      <th>mean_test_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.966755</td>\n",
              "      <td>0.965471</td>\n",
              "      <td>0.989328</td>\n",
              "      <td>0.944070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.978728</td>\n",
              "      <td>0.978301</td>\n",
              "      <td>0.990771</td>\n",
              "      <td>0.966719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.973417</td>\n",
              "      <td>0.972788</td>\n",
              "      <td>0.988306</td>\n",
              "      <td>0.958737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.969422</td>\n",
              "      <td>0.968543</td>\n",
              "      <td>0.989468</td>\n",
              "      <td>0.949421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.966764</td>\n",
              "      <td>0.965585</td>\n",
              "      <td>0.989345</td>\n",
              "      <td>0.944105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.964764</td>\n",
              "      <td>0.963384</td>\n",
              "      <td>0.989345</td>\n",
              "      <td>0.940105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c04f612-abd6-4d94-b9f7-43327d2cdd4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c04f612-abd6-4d94-b9f7-43327d2cdd4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c04f612-abd6-4d94-b9f7-43327d2cdd4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  param_alpha  mean_test_accuracy  mean_test_f1  mean_test_precision  \\\n",
              "0           1            0.966755      0.965471             0.989328   \n",
              "1         0.1            0.978728      0.978301             0.990771   \n",
              "2        0.01            0.973417      0.972788             0.988306   \n",
              "3       0.001            0.969422      0.968543             0.989468   \n",
              "4      0.0001            0.966764      0.965585             0.989345   \n",
              "5     0.00001            0.964764      0.963384             0.989345   \n",
              "\n",
              "   mean_test_recall  \n",
              "0          0.944070  \n",
              "1          0.966719  \n",
              "2          0.958737  \n",
              "3          0.949421  \n",
              "4          0.944105  \n",
              "5          0.940105  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}